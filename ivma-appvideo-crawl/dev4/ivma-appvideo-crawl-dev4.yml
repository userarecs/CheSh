server:
  port: 8002

#http://localhost:8000
eureka:
  client:
    serviceUrl:
      defaultZone: http://172.16.12.2:8000/eureka/
crawl:
  type: 4
  
spring:
  application:
    name: ivma-appvideo-crawl${crawl.type}
  thymeleaf:
    cache: false

  datasource:
    driverClassName: oracle.jdbc.driver.OracleDriver
    #url: jdbc:oracle:thin:@(description=(address_list= (address=(host=172.16.24.75)(protocol=tcp)(port=1521))(address=(host=172.16.24.76)(protocol=tcp) (port=1521)) (load_balance=yes)(failover=on))(connect_data=(service_name= orcl)))
    url: jdbc:oracle:thin:@172.16.39.212:1521:rac2
    username: ivma
    password: ivma

  cloud:
    stream:
      bindings:
        #配置自己定义的通道与哪个中间件交互
        shop_input: #ShopChannel里Input和Output的值
          destination: QUEUE.APPINFOS #目标主题
        shop_output:
          destination: QUEUE.APPINFOS
      default-binder: kafka #默认的binder是kafka
      
  kafka:
    # 指定kafka 代理地址，可以多个
    bootstrap-servers: 172.16.12.12:9091 #kafka服务地址
    
    consumer:
      group-id: consumer1
      auto-offset-reset: earliest
      enable-auto-commit: true
      auto-commit-interval: 100
      # 指定消息key和消息体的编解码方式
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      
    producer:
      # 指定消息key和消息体的编解码方式
      key-serializer: org.apache.kafka.common.serialization.ByteArraySerializer
      value-serializer: org.apache.kafka.common.serialization.ByteArraySerializer
      # 每次批量发送消息的数量
      batch-size: 16384
      buffer-memory: 33554432
      client-id: producer1

mybatis:
  #实体类的包路径
  type-aliases-package: com.certus.ivma.entity
  #扫描classpath下mapper目录下的所有.xml文件
  mapper-locations: classpath:mapper/*.xml

logging:
  path: D:/rome/
  file: springbootdemo.log
  #TARCE < DEBUG < INFO 默认 < WARN < ERROR < FATAL
  level:
    root: INFO
    com:
      certus:
        ivma:
          mapper: DEBUG # 打印sql

#spring线程池
thread_pool:
  schedule_executor:
    core_pool_size: 5
    max_pool_size: 5
    queue_capacity: 0
    name_prefix: schedule-executor-
    keep_alive_seconds: 10
  execute_executor:
    core_pool_size: 5
    max_pool_size: 500
    queue_capacity: 0
    name_prefix: execute-executor-
    keep_alive_seconds: 10
  
app:
  shell:
    path: http://localhost:80

constants:
  task:
    execute:
      max:
        second: 60
  host:
    keepalive:
      second: 60
